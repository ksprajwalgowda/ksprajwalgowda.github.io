<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/css/bootstrap.min.css" integrity="sha384-B0vP5xmATw1+K9KRQjQERJvTumQW0nPEzvF6L/Z6nronJ3oUOFUFpCjEUQouq2+l" crossorigin="anonymous">

    <title>emotion</title>
  </head>
  <body>
    
    <style>
        @media (max-width:800px){
            .emo{
                padding: 70px;
            }
        }
    </style>
    <div class="container">
        <div class="row pt-4 mt-4">
            <div class="col col-12 col-md-8 col-lg-8 ">
                <div>
                    <video id="vid" height="100%" width="100%"></video>
                </div>
            </div>
            <div class="col col-12 col-md-4 col-lg-4 emo">
                <div><b>Results</b></div>
  
                <div id="emotion">Emotion: -</div>
                <div id="emotion1"></div>

                <button class="btn btn-primary" onclick="runit()">capture emotion</button>
            </div>
        </div>
    </div>






    <script src="https://sdk.morphcast.com/mphtools/v1.0/mphtools.js"></script>
    <script src="https://ai-sdk.morphcast.com/v1.14/ai-sdk.js"></script>
  <script>

    document.addEventListener("DOMContentLoaded", () => {
      var video = document.getElementById("vid");
      var mediaDevices = navigator.mediaDevices;
      vid.muted = true;
  
      // Accessing the user camera and video.
      mediaDevices
        .getUserMedia({
        video: true,
        audio: false,
        })
        .then((stream) => {
  
        // Changing the source of video to current stream.
        video.srcObject = stream;
        video.addEventListener("loadedmetadata", () => {
          video.play();
        });
        })
        .catch(alert);
    });



// Complete code documentation of MorphCast AI SDK, here:
// https://ai-sdk.morphcast.com/latest/index.html




CY.loader()
   .licenseKey("d48dfc9880c32dc64f4e8b766604c34c53ff97155c5d")
   
   .addModule(CY.modules().FACE_EMOTION.name)
   .load()
   .then(({ start, stop }) => start());
   
   const emo_div = document.querySelector("#emotion");
   const emo1_div = document.querySelector("#emotion1");
   var ee;
   
   
   window.addEventListener(CY.modules().FACE_EMOTION.eventName, (evt) => {
     ee = evt.detail.output.dominantEmotion;
    emo_div.innerHTML = 'Emotion: ' + evt.detail.output.dominantEmotion;
   });

function runit(){

emo1_div.innerHTML = 'emotion captured: ' + ee;
}
  </script>
    <!-- Optional JavaScript; choose one of the two! -->

    <!-- Option 1: jQuery and Bootstrap Bundle (includes Popper) -->
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.bundle.min.js" integrity="sha384-Piv4xVNRyMGpqkS2by6br4gNJ7DXjqk09RmUpJ8jgGtD7zP9yug3goQfGII0yAns" crossorigin="anonymous"></script>

    <!-- Option 2: Separate Popper and Bootstrap JS -->
    <!--
    <script src="https://code.jquery.com/jquery-3.5.1.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.0/dist/js/bootstrap.min.js" integrity="sha384-+YQ4JLhjyBLPDQt//I+STsc9iw4uQqACwlvpslubQzn4u2UU2UFM80nGisd026JF" crossorigin="anonymous"></script>
    -->
  </body>
</html>